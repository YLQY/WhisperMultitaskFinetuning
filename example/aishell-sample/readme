注意，example中data中的wav.scp中的音频路径

目前只支持两种任务

id|语种|任务类型
eg:
BAC009S0150W0010|chinese|translate
BAC009S0150W0006|chinese|transcribe



# 训练数据
data:
  train:
    wav_scp: "/mnt/f/wsl/asr_large_model/whisper-multitask-finetuning/example/aishell-sample/data/wav.scp"
    text: "/mnt/f/wsl/asr_large_model/whisper-multitask-finetuning/example/aishell-sample/data/text"
  test:
    wav_scp: "/mnt/f/wsl/asr_large_model/whisper-multitask-finetuning/example/aishell-sample/data/wav.scp"
    text: "/mnt/f/wsl/asr_large_model/whisper-multitask-finetuning/example/aishell-sample/data/text"

# 预测的方法
predict:
  # 使用的模型，如果是large-v2用到了peft，则model.is_large_model参数为True
  model_path: "/mnt/f/wsl/asr_large_model/whisper-multitask-finetuning/example/aishell-sample/model"
  # 预测的结果
  result_file: "./data/result"
  eval: 
    wav_scp: "/mnt/f/wsl/asr_large_model/whisper-multitask-finetuning/example/aishell-sample/data/wav.scp"
    text: "/mnt/f/wsl/asr_large_model/whisper-multitask-finetuning/example/aishell-sample/data/text"


# 关于模型训练的参数
model:
  # 微调模型的位置
  model_path: "/mnt/f/wsl/asr_large_model/whisper_model/whisper-large-v2"
  # 如果是largev2模型，则为True，其他则为False
  is_large_model: True
  # 数据处理的-未知
  data_collator:
    forward_attention_mask: False

  # 模型训练参数
  model_train_argv:
    # 输出模型结果
    out_model_path: "./model"
    # 继续训练模型，空为不继续训练
    resume_from_checkpoint : ""
    # 训练的batch
    per_device_train_batch_size: 1
    # 测试的batch
    per_device_eval_batch_size: 1
    gradient_accumulation_steps: 1
    # 训练多少轮
    num_train_epochs: 1
    # 学习率
    learning_rate: 0.0001
    # 每迭代多少次，打印loss
    logging_steps: 2
    fp16: False
    warmup_steps: 50
    evaluation_strategy: "epoch"
    generation_max_length: 128
    remove_unused_columns: False
    label_names:
      - labels

